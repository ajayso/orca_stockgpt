https://github.com/LinkSoul-AI/LLaSM
https://github.com/BradyFU/Awesome-Multimodal-Large-Language-Models
https://www.v7labs.com/blog/multimodal-deep-learning-guide


LLMs when it comes fine tuning generally resort to few shot learning, Chain of thoughts, tree of thoughts or some form of prompt engineering. Not going into very specific details by the time invested in training using prompt engineering and returns from an accuracy work well for simpler tasks like QnA, context based text generation. When it comes to large problem statement one may resort to CoT, which soon we figure out has limitation when it comes to mathematical ability. Soon we move to LLM + planner, which are more designed to solve problems for specific domains. We soon see ourselves in augmentation techniques zone where we start questioning for complex problems involving reasoning and with mathematical ability. The next gradual step one moves into Autonomous LLM agents which throw a set of components from  planning(task decomposition), action, memory(short and long term) and tools (where LLMs cant solve we go external) and ofcourse LLM at the centre. Having gone this path we soon reason and ask is there a more better way to solve these problems of complex reasoning apparently going back to the basic Multimodal which involve modals specifically for the domain, number reasonining can work in tandem with LLMs. Of course one had to cross the bridge of adapor which maps the output from these specific models, to text embedding of LLMs. Now do you think have I plotted the broad spectrum of journey of learning LLM from an applicability point of view